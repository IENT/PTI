{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"./Bilder/Netz.png\" style=\"float: center;height: 50em;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib\n",
    "#matplotlib.use('nbagg')\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_approximate_num_macs(setup):\n",
    "    width = 28\n",
    "    height = 28\n",
    "    n_channels = 1\n",
    "    macs = 0\n",
    "    for conv in setup:\n",
    "        macs += conv[\"kernel_size\"] * conv[\"kernel_size\"] * width * height * n_channels * conv[\"num_channels\"]\n",
    "\n",
    "        width = width / conv[\"max_pooling\"]\n",
    "        height = height / conv[\"max_pooling\"]\n",
    "        n_channels = conv[\"num_channels\"]\n",
    "\n",
    "    macs += width * height * n_channels * 10\n",
    "    return macs\n",
    "\n",
    "import copy\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, setup):\n",
    "        super(Net, self).__init__()\n",
    "        # Parameters\n",
    "        self.intermediate_outputs = {}\n",
    "\n",
    "        self.setup = setup\n",
    "\n",
    "        # Input layer\n",
    "        in_channels = 1\n",
    "        width = 28\n",
    "        height = 28\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for layer_params in setup:\n",
    "            self.convs.append(nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels, \n",
    "                    out_channels=layer_params[\"num_channels\"],\n",
    "                    kernel_size=layer_params[\"kernel_size\"],\n",
    "                    stride=1,\n",
    "                    padding=\"same\",\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=layer_params[\"max_pooling\"], stride=layer_params[\"max_pooling\"]),\n",
    "            ))\n",
    "\n",
    "            in_channels = layer_params[\"num_channels\"]\n",
    "            width = width // layer_params[\"max_pooling\"]\n",
    "            height = height // layer_params[\"max_pooling\"]\n",
    "\n",
    "        # Fully connected layer\n",
    "        fc_in = in_channels * width * height\n",
    "        fc_out = 10  # channels\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            in_features=fc_in, out_features=fc_out\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.intermediate_outputs['in'] = x.detach().numpy()\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x)\n",
    "            self.intermediate_outputs['conv' + str(i+1)] = x.detach().numpy()\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        self.intermediate_outputs['fc'] = x.detach().numpy()\n",
    "        \n",
    "        output = F.softmax(x, dim=1)\n",
    "        self.intermediate_outputs['output'] = output.detach().numpy()\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def reset_all_weights(self):\n",
    "        \"\"\"\n",
    "        refs:\n",
    "            - https://discuss.pytorch.org/t/how-to-re-set-alll-parameters-in-a-network/20819/6\n",
    "            - https://stackoverflow.com/questions/63627997/reset-parameters-of-a-neural-network-in-pytorch\n",
    "            - https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "        \"\"\"\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def weight_reset(m: nn.Module):\n",
    "            # - check if the current module has reset_parameters & if it's callable called it on m\n",
    "            reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "            if callable(reset_parameters):\n",
    "                m.reset_parameters()\n",
    "\n",
    "        # Applies fn recursively to every submodule see: https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "        self.apply(fn=weight_reset)\n",
    "\n",
    "\n",
    "def training_step(data, target, model, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.intermediate_outputs['target'] = target\n",
    "    return output, loss\n",
    "\n",
    "def test_step(data, target, model):\n",
    "    output = model(data)\n",
    "    test_loss = F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "    pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    model.intermediate_outputs['target'] = target\n",
    "    return output, test_loss, correct\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            _, test_loss_step, correct_step = test_step(data, target, model)\n",
    "            test_loss += test_loss_step\n",
    "            correct += correct_step\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    model.intermediate_outputs['test_loss'] = test_loss\n",
    "    model.intermediate_outputs['test_acc'] = test_acc\n",
    "\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    #     test_loss, correct, len(test_loader.dataset),\n",
    "    #     test_acc))\n",
    "\n",
    "    return model.intermediate_outputs\n",
    "\n",
    "\n",
    "def train_test_step(logging_interval, data, target, model, device, train_loader, test_loader, optimizer, epoch, batch_idx):\n",
    "    output, loss = training_step(data, target, model, optimizer)\n",
    "    intermediate_outputs_train = copy.deepcopy(model.intermediate_outputs)\n",
    "\n",
    "    if batch_idx % logging_interval == 0:\n",
    "        # print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #    100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "        train_loss = loss.item()\n",
    "        train_acc  = 100. * torch.sum(output.argmax(dim=1) == target).item() / len(target)\n",
    "\n",
    "        # Test\n",
    "        intermediate_outputs_test = test(model, device, test_loader)\n",
    "        model.train()\n",
    "\n",
    "        intermediate_outputs_train['train_loss'] = train_loss\n",
    "        intermediate_outputs_train['train_acc'] = train_acc\n",
    "    else:\n",
    "        intermediate_outputs_test = None\n",
    "        \n",
    "    return intermediate_outputs_train, intermediate_outputs_test\n",
    "\n",
    "def plot_cost_functions(axs, train_accs, test_accs, train_losses, test_losses):\n",
    "    \n",
    "    ax = axs[0]  # Accuracy\n",
    "\n",
    "    max_visible_points = 100\n",
    "    xtmp = np.arange(len(train_accs) - min(len(train_accs), max_visible_points), len(train_accs))\n",
    "    if not ax.lines:  # decorate\n",
    "        ax.plot(xtmp, train_accs)\n",
    "        ax.plot(xtmp, test_accs)\n",
    "        ax.set_xlabel('Batch Number'); ax.set_ylabel('Percentages')\n",
    "        ax.legend(['Training Accuracy (' + str(train_accs[-1]) + '%)', 'Test Accuracy (' + str(test_accs[-1]) + '% / ' + str(max(test_accs)) + '%)'])\n",
    "    else:  # update\n",
    "        ax.lines[0].set_data(xtmp, train_accs[len(train_accs) - min(len(train_accs), max_visible_points):])\n",
    "        ax.lines[1].set_data(xtmp, test_accs[len(train_accs) - min(len(train_accs), max_visible_points):])\n",
    "        ax.legend(['Training Accuracy (' + str(train_accs[-1]) + '%)', 'Test Accuracy (' + str(test_accs[-1]) + '% / ' + str(max(test_accs)) + '%)'])\n",
    "        ax.relim(); ax.autoscale_view(True, True, True)\n",
    "\n",
    "    print('Training Accuracy (' + str(train_accs[-1]) + '%),\\t Test Accuracy (' + str(test_accs[-1]) + '% / Best: ' + str(max(test_accs)) + '%)')\n",
    "    ax = axs[1]  # Loss\n",
    "\n",
    "    xtmp = np.arange(len(train_losses))\n",
    "    if not ax.lines:  # decorate\n",
    "        ax.plot(train_losses)\n",
    "        ax.plot(test_losses)\n",
    "        ax.set_xlabel('Batch Number'); \n",
    "        ax.legend(['Training Loss', 'Test Loss'])\n",
    "    else:  # update\n",
    "        ax.lines[0].set_data(xtmp, train_losses)\n",
    "        ax.lines[1].set_data(xtmp, test_losses)\n",
    "        ax.relim(); ax.autoscale_view(True, True, True)\n",
    "\n",
    "\n",
    "def plot_test_labels(ax, target, act_fully, act_softmax):\n",
    "\n",
    "    three_red = np.repeat('r', 3)\n",
    "\n",
    "    softmax_topthree = sorted(act_softmax)[-3:]\n",
    "    percentages =  100*np.maximum(softmax_topthree, 0)\n",
    "    target = int(target)\n",
    "    idx_topthree = np.argpartition(act_fully, -3)[-3:]\n",
    "    if not ax.containers:                \n",
    "        ax.set_xticks([]); ax.set_yticks(np.arange(3)); \n",
    "    else:\n",
    "        ax.containers[0].remove()\n",
    "\n",
    "    ax.set_yticklabels(idx_topthree)\n",
    "\n",
    "    colors = three_red.copy()\n",
    "    colors[idx_topthree == target] = 'g'  # Mark target class in green\n",
    "    ax.barh(np.arange(3), percentages, align='center', color=colors)\n",
    "    for m, v in enumerate(percentages):\n",
    "        ax.text(v + 0.05, m , f\"{v:2.2f}%\", color='black')\n",
    "\n",
    "    ax.set_xlim((0, 100))\n",
    "\n",
    "def plot_image(im, ax, **kwargs):\n",
    "    if not ax.images:  # Decorate\n",
    "        ax.imshow(im, cmap='gray', **kwargs)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "    else:  # Update\n",
    "        ax.images[0].set_array(im)\n",
    "\n",
    "\n",
    "def plot_weights(weights, ax, **kwargs):\n",
    "    (ch_out, ch_in, h, w) = weights.shape\n",
    "\n",
    "    weights2 = weights.transpose(1, 2, 0, 3).reshape(ch_in*h, ch_out*w)\n",
    "\n",
    "    if not ax.images:  # Decorate\n",
    "        ax.imshow(weights2, cmap='gray', **kwargs)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "        if ch_out > 1:\n",
    "            for tmp in range(ch_out):\n",
    "                ax.axvline(tmp*w-0.5, color='black', lw=1)\n",
    "        if ch_in > 1:\n",
    "            for tmp in range(ch_in):\n",
    "                ax.axhline(tmp*h-0.5, color='black', lw=1)\n",
    "    \n",
    "    else:  # Update\n",
    "        ax.images[0].set_array(weights2)\n",
    "\n",
    "\n",
    "def plot_activations(act, ax, **kwargs):\n",
    "    (ch_out, h, w) = act.shape\n",
    "\n",
    "    act2 = act.transpose(1, 0, 2).reshape(h, ch_out*w)\n",
    "    ch_in = 1\n",
    "    if ch_out > 15:\n",
    "        act2 = np.concatenate(np.split(act2, 2, axis=1))\n",
    "        ch_out = ch_out // 2\n",
    "        ch_in = ch_in * 2\n",
    "\n",
    "    if not ax.images:  # Decorate\n",
    "\n",
    "        ax.imshow(act2, cmap='gray', **kwargs)\n",
    "        ax.set_xticks([]); ax.set_yticks([]) \n",
    "\n",
    "        if ch_out > 1:\n",
    "            for tmp in range(ch_out):\n",
    "                ax.axvline(tmp*w-0.5, color='black', lw=1)\n",
    "\n",
    "        if ch_in > 1:\n",
    "            for tmp in range(ch_in):\n",
    "                ax.axhline(tmp*h-0.5, color='black', lw=1)\n",
    "\n",
    "    else:  # Update\n",
    "        ax.images[0].set_array(act2)\n",
    "\n",
    "\n",
    "def plot_activations_figure(axs, input, act1, act2, act3, act4, weights1, weights2):\n",
    "    plot_image(input, axs[0][0])\n",
    "    plot_activations(act1, axs[0][1])\n",
    "    plot_activations(act2, axs[0][2])\n",
    "    plot_activations(act3[:,np.newaxis,np.newaxis], axs[0][3])\n",
    "    plot_activations(act4[:,np.newaxis,np.newaxis], axs[0][4])\n",
    "    plot_image(input, axs[1][0])\n",
    "    plot_weights(weights1, axs[1][1])\n",
    "    plot_weights(weights2, axs[1][2])\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def optimize_and_plot_model(model, learning_rate, batch_size, num_steps):\n",
    "    plt.cla()\n",
    "    plt.ion()\n",
    "    subplot_shape = (10, 9)\n",
    "\n",
    "    pos_test = (5, 0)\n",
    "    axs_test = [\n",
    "        plt.subplot2grid(subplot_shape, (0 + pos_test[0], 0 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (0 + pos_test[0], 1 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (0 + pos_test[0], 2 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (0 + pos_test[0], 3 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (1 + pos_test[0], 0 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (1 + pos_test[0], 1 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (1 + pos_test[0], 2 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (1 + pos_test[0], 3 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (2 + pos_test[0], 0 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (2 + pos_test[0], 1 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (2 + pos_test[0], 2 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (2 + pos_test[0], 3 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (3 + pos_test[0], 0 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (3 + pos_test[0], 1 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (3 + pos_test[0], 2 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (3 + pos_test[0], 3 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (4 + pos_test[0], 0 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (4 + pos_test[0], 1 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (4 + pos_test[0], 2 + pos_test[1])),\n",
    "        plt.subplot2grid(subplot_shape, (4 + pos_test[0], 3 + pos_test[1])),\n",
    "    ]\n",
    "    axs_test[0].figure.set_size_inches(20, 10)\n",
    "    axs_test[0].margins(0.1)\n",
    "    axs = [\n",
    "        plt.subplot2grid(subplot_shape, (0, 0), colspan=4, rowspan=2),\n",
    "        plt.subplot2grid(subplot_shape, (2, 0), colspan=4, rowspan=2),\n",
    "    ] \n",
    "\n",
    "    ax_model_params = plt.subplot2grid(subplot_shape, (4, 0), colspan=4, rowspan=1)\n",
    "\n",
    "    axs_weights = [\n",
    "        [\n",
    "            plt.subplot2grid(subplot_shape, (0, 5), rowspan=2, colspan=2),\n",
    "            plt.subplot2grid(subplot_shape, (3, 5), rowspan=2, colspan=2),\n",
    "            plt.subplot2grid(subplot_shape, (5, 5), rowspan=2, colspan=2),\n",
    "            plt.subplot2grid(subplot_shape, (7, 5), rowspan=2, colspan=2),\n",
    "            plt.subplot2grid(subplot_shape, (9, 5), rowspan=1, colspan=2),\n",
    "        ],\n",
    "        [\n",
    "            plt.subplot2grid(subplot_shape, (0, 7), rowspan=2, colspan=2),\n",
    "            plt.subplot2grid(subplot_shape, (3, 7), rowspan=2, colspan=2),\n",
    "            plt.subplot2grid(subplot_shape, (5, 7), rowspan=2, colspan=2),\n",
    "        ],\n",
    "    ]\n",
    "    axs_weights[0][0].set_title(\"Input Picture\")\n",
    "    axs_weights[0][1].set_title(\"Output of Layer 1\")\n",
    "    axs_weights[0][2].set_title(\"Output of Layer 2\")\n",
    "    axs_weights[0][3].set_title(\"Output of Fully Connected Layer\")\n",
    "    axs_weights[0][4].set_title(\"Output of Fully Connected Layer (after Softmax)\")\n",
    "\n",
    "    axs_weights[1][0].set_title(\"Input Picture\")\n",
    "    axs_weights[1][1].set_title(\"Filters of Layer 1\")\n",
    "    axs_weights[1][2].set_title(\"Filters of Layer 2\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Training settings\n",
    "    test_batch_size = 24\n",
    "    epochs = num_steps\n",
    "    random_seed = 1\n",
    "    logging_interval = 10\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    test_kwargs = {'batch_size': test_batch_size}\n",
    "\n",
    "    # Data\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    dataset2 = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    # Model\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    model_operations = get_approximate_num_macs(model.setup)\n",
    "\n",
    "    ax_model_params.text(0.5, 0, \"Num parameters: \" + str(int(model_parameters)) + \"\\n\" + \"Num operations per picture: \" + str(int(model_operations)), horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "    ax_model_params.get_xaxis().set_visible(False)\n",
    "    ax_model_params.get_yaxis().set_visible(False)\n",
    "    ax_model_params.axis(\"off\")\n",
    "    \n",
    "    print(\"Num parameters: \" + str(int(model_parameters)) + \"\\n\" + \"Num operations per picture: \" + str(int(model_operations)))\n",
    "\n",
    "    # Optimizer\n",
    "    intermediate_outputs_test = None\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            intermediate_outputs_train, intermediate_outputs_test0 = train_test_step(logging_interval, data, target, model, device, train_loader, test_loader, optimizer, epoch, batch_idx)\n",
    "            if batch_idx % logging_interval == 0:\n",
    "                intermediate_outputs_test = intermediate_outputs_test0\n",
    "                train_losses.append(intermediate_outputs_train['train_loss'])\n",
    "                train_accs.append(intermediate_outputs_train['train_acc'])\n",
    "                test_losses.append(intermediate_outputs_test['test_loss'])\n",
    "                test_accs.append(intermediate_outputs_test['test_acc'])\n",
    "\n",
    "                l = {}\n",
    "                for idx in range(intermediate_outputs_test['in'].shape[0]):\n",
    "                    target = intermediate_outputs_test['target'][idx]\n",
    "                    act4 = intermediate_outputs_test['fc'][idx, :]\n",
    "                    output = intermediate_outputs_test['output'][idx, :]\n",
    "\n",
    "                    if target not in l:\n",
    "                        l[target] = {}\n",
    "                        l[target][\"output\"] = output\n",
    "                        l[target][\"act4\"] = act4\n",
    "                    else:\n",
    "                        l[target] += output\n",
    "                        l[target][\"output\"] = output\n",
    "                        l[target][\"act4\"] = act4\n",
    "                    \n",
    "\n",
    "                for idx in range(10):\n",
    "                    im1 = intermediate_outputs_test['in'][idx, 0, :, :]\n",
    "                    act4 = intermediate_outputs_test['fc'][idx, :]\n",
    "                    output = intermediate_outputs_test['output'][idx, :]\n",
    "                    target = intermediate_outputs_test['target'][idx]\n",
    "\n",
    "                    ax_test = axs_test[2*idx]\n",
    "                    ax_label = axs_test[2*idx + 1]\n",
    "                    ax_label.clear()\n",
    "\n",
    "                    plot_image(im1, ax_test)\n",
    "\n",
    "                    plot_test_labels(ax_label, target, act4, output)\n",
    "\n",
    "                plot_cost_functions(axs, train_accs, test_accs, train_losses, test_losses)\n",
    "\n",
    "                idx = 0\n",
    "                im1 = intermediate_outputs_train['in'][idx, 0, :, :]\n",
    "\n",
    "                weights1 = model.convs[0][0].weight.data.detach().numpy()\n",
    "                weights2 = model.convs[1][0].weight.data.detach().numpy()\n",
    "\n",
    "                act1 = intermediate_outputs_train['conv1'][idx, :, :, :]\n",
    "                act2 = intermediate_outputs_train['conv2'][idx, :, :, :]\n",
    "                act3 = intermediate_outputs_train['fc'][idx, :]\n",
    "                act4 = intermediate_outputs_train['output'][idx, :]\n",
    "                \n",
    "                plot_activations_figure(axs_weights, im1, act1, act2, act3, act4, weights1, weights2)\n",
    "                #clear_output(wait=True)\n",
    "                \n",
    "                plt.savefig(\"current_training_status.png\")\n",
    "\n",
    "\n",
    "        intermediate_outputs_train['train_loss'] = train_losses\n",
    "        intermediate_outputs_train['train_acc'] = train_accs\n",
    "        intermediate_outputs_test['test_loss'] = test_losses\n",
    "        intermediate_outputs_test['test_acc'] = test_accs\n",
    "        \n",
    "        #scheduler.step()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1\n",
    "\n",
    "In dieser Aufgabe wird ein einfaches neuronales Netzwerk zur Klassifikation von Zahlen erstellt und trainier. Die erste Aufgabe ist es, gute Trainingsparameter für das vordefinierte CNN zu finden. Danach wird die Architektur des CNNs angepasst und für verschiedene Anwendungsszenarien optimiert.\n",
    "\n",
    "Subtasks:\n",
    "1. Finde eine passende Lernrate und Batch-Größe, sodass das Netzwerk mindestens 80% Genauigkeit auf dem Testset erreicht.\n",
    "2. Finde eine Netzwerk-Architektur, sodass mindestens 95% Genauigkeit auf dem Testset erreicht wird.\n",
    "3. Optimiere eine Netzwerkarchitektur mit weniger als 25000 Operationen pro bild, die trotzdem mindestens 85% Genauigkeit auf dem Testset erreicht. Ein solches CNN würde benutzt, wenn die Rechenpower sehr beschränkt ist (z.B. auf einem Mikrocontroller oder Smartphone).\n",
    "4. Optimiere ein möglichst kleines CNN mit weniger als 2500 Parametern, dass trotzdem mindesten 85% genauigkeit erzielt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In der Setup Variable wird die Architektur des CNNs definiert. Diese kann verwendet werden um die Architektur des Netzwerks anzupassen.\n",
    "# Eine weiter Ebene kann dem Netzwerk hinzugefügt werden, indem ein weiterer Eintrag der Liste hinzugefügt wird. \n",
    "# Dabei müssen die folgenden Parameter definiert sein:\n",
    "#   - kernel_size: Größe des Filters in einer \"convolutional layer\" (z.B. eine Filter-Größe von 5 würde zu einem Filter der Größe 5x5 korrespondieren)\n",
    "#   - num_channels: Anzahl Ausgabe-Kanälen für diese Ebene = Anzahl filter dieser Ebene\n",
    "#   - max_pooling: Größe des \"max-poolings\". Z.B. bei einem max-pooling der Größe 2 würde von jedem 2x2 block der größte Wert übertragen\n",
    "setup = [\n",
    "    {\"kernel_size\": 5, \"num_channels\":  4, \"max_pooling\": 2},\n",
    "    {\"kernel_size\": 3, \"num_channels\":  8, \"max_pooling\": 2},\n",
    "]\n",
    "\n",
    "model = Net(setup)\n",
    "\n",
    "model_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model_operations = get_approximate_num_macs(model.setup)\n",
    "\n",
    "print(\"Num parameters: \" + str(int(model_parameters)) + \"\\n\" + \"Num operations per picture: \" + str(int(model_operations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Die Parameter für das Training werden hier definiert. Falsche oder schlecht gewählte Parameter können in instabilen Training resultieren.\n",
    "# Eine gute Wahl der Trainingsparameter ist demnach äußerst wichtig\n",
    "learning_rate = 1\n",
    "batch_size = 64\n",
    "\n",
    "# Training and plotting\n",
    "optimize_and_plot_model(model, learning_rate, batch_size, num_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >>Weiter zum  [__Feedback__](Feedback.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
